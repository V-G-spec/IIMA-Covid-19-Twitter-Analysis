{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "twitter_covid.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGg-Y2Og2Oja"
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import pprint\n",
        "import datetime, time\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iODNNRt2Ojj"
      },
      "source": [
        "CONSUMER_KEY = {\"\":\"\"}\n",
        "\n",
        "CONSUMER_SECRET = {\"\":\"\"}\n",
        "\n",
        "environment_names_30_day = {\"\":\"\"}\n",
        "environment_names_full = {\"\":\"\"}\n",
        "\n",
        "user = \"Marichi\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL-Tcj9z2Ojq"
      },
      "source": [
        "\n",
        "auth = tweepy.AppAuthHandler(CONSUMER_KEY[user], CONSUMER_SECRET[user])\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeN6upul2Ojw"
      },
      "source": [
        "start_date = datetime.datetime(2020, 6, 9, 0, tzinfo = datetime.timezone(datetime.timedelta(hours = 0))) #5 June\n",
        "start_time = start_date\n",
        "end_date_object = datetime.datetime(2020, 6, 15, 0, tzinfo = datetime.timezone(datetime.timedelta(hours = 0))) #12 June\n",
        "\n",
        "count=0\n",
        "list_of_records = []\n",
        "for page in tweepy.Cursor(api.search, q='blacklivesmatter' + \" until:\" + str(int(end_date_object.timestamp())) \n",
        "                    + \" since:\"+ str(int(start_time.timestamp())) + \" -filter:retweets\", tweet_mode='extended', count=100).pages():\n",
        "    # process status here\n",
        "    \n",
        "    for tweet in page:\n",
        "        list_of_records.append(tweet._json)\n",
        "\n",
        "    print(\"Start:\", page[-1].created_at, \" End: \", page[0].created_at)\n",
        "    print(\"First ID:\", page[-1].id, \" Last ID: \", page[0].id)\n",
        "    print(len(list_of_records))\n",
        "\n",
        "df = pd.DataFrame.from_records(list_of_records)\n",
        "df.to_json(\"Content/main.json\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkMbyPLP2Oj6"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(list_of_records, open(\"Output/tweets.p\",\"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPgT1Xej2Oj9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f11355d0-741e-4baa-f896-2f0edf5e0d9c"
      },
      "source": [
        "print(list_of_records[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'created_at': 'Sun Jun 14 23:59:59 +0000 2020', 'id': 1272317897130549254, 'id_str': '1272317897130549254', 'full_text': 'Yaa Ahall pls üôè üôè üôè save me from myself and put me in the right direction. cuz I need you in my life, and to everyone out there l love you all ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏èless love one another white or black we are same.#BlackLivesMatter üì¢üîäüîäüîä', 'truncated': False, 'display_text_range': [0, 220], 'entities': {'hashtags': [{'text': 'BlackLivesMatter', 'indices': [198, 215]}], 'symbols': [], 'user_mentions': [], 'urls': []}, 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'}, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 1269042262291423249, 'id_str': '1269042262291423249', 'name': '@S.Dihaj', 'screen_name': 's_dihaj', 'location': '', 'description': 'am beautiful and I love myself and my family I Love my religion my friends and  I thank God  for my life.Allha I Love you. l know with you every thing is posbl.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 18, 'listed_count': 0, 'created_at': 'Fri Jun 05 23:04:23 +0000 2020', 'favourites_count': 16, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 10, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1269313167043198979/RoI7I0vu_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1269313167043198979/RoI7I0vu_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': None, 'follow_request_sent': None, 'notifications': None, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 1, 'favorited': False, 'retweeted': False, 'lang': 'en'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaxBuQuK2OkC"
      },
      "source": [
        "#Can get my access token from the block after the one after this one\n",
        "import json\n",
        "a\n",
        "# Enter your keys/secretbs as strings in athe following fields #These are Aditya's\n",
        "credentials = {}\n",
        "credentials['CONSUMER_KEY'] = \"\"\n",
        "credentials['CONSUMER_SECRET'] = \"\"\n",
        "credentials['ACCESS_TOKEN'] = \"\"\n",
        "credentials['ACCESS_SECRET'] = \"\"\n",
        "\n",
        "# Save the credentials object to file\n",
        "with open(\"twitter_credentials.json\", \"w\") as file:\n",
        "    json.dump(credentials, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UdWhOKN2OkG"
      },
      "source": [
        "from twython import Twython\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "start_date = datetime.datetime(2020,5,29)\n",
        "end_date = datetime.datetime(2020,6,2)\n",
        "timedelta = datetime.timedelta(minutes = 2)\n",
        "\n",
        "# Load credentials from json file\n",
        "with open(\"twitter_credentials.json\", \"r\") as file:\n",
        "    creds = json.load(file)\n",
        "\n",
        "# Instantiate an object\n",
        "#python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n",
        "python_tweets = Twython(credentials['CONSUMER_KEY'], access_token=credentials['ACCESS_TOKEN'])\n",
        "\n",
        "# Create our query\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHcak03Q2OkK"
      },
      "source": [
        "#Get access token\n",
        "APP_KEY = ''\n",
        "APP_SECRET = ''\n",
        "\n",
        "twitter = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
        "ACCESS_TOKEN = twitter.obtain_access_token()\n",
        "print(ACCESS_TOKEN)\n",
        "# ACCESS_TOKEN = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnpQQktJ2OkO"
      },
      "source": [
        "APP_KEY = ''\n",
        "ACCESS_TOKEN = ''\n",
        "import datetime\n",
        "from twython import Twython\n",
        "start_date = datetime.datetime(2020,6,4,10,30)\n",
        "end_date = datetime.datetime(2020,6,4,10,40)\n",
        "timedelta = datetime.timedelta(minutes=10)\n",
        "\n",
        "import twython\n",
        "python_tweets = Twython(APP_KEY, access_token=ACCESS_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGyl7tK52OkS"
      },
      "source": [
        "## import time \n",
        "\n",
        "def get_query_object(start_date_object, end_date_object, timedelta):\n",
        "    datadict = {'date':[], 'full_text':[], 'hashtag_mentions':[], \n",
        "                'url_mentions':[],'user_mentions':[],'language_iso':[],'user_reply':[],'status_reply':[],\n",
        "                'user_id':[],'user_id_name':[],'user_screen_name':[],'user_location':[],\n",
        "                'user_desc':[],'user_followers':[],'user_friends':[],'user_created_at':[],'user_favorites_count':[],\n",
        "                'user_statuses':[],'lang':[],'status_retweet':[],'status_favorites':[],'geo':[],'coordinates':[],'place':[]}\n",
        "    end_date_epoch = int(end_date_object.timestamp())\n",
        "    timestep = timedelta.seconds\n",
        "    start_time_epoch = int(start_date_object.timestamp())\n",
        "    while start_time_epoch < end_date_epoch:\n",
        "#         print(start_time_epoch)\n",
        "#         print(end_date_epoch)\n",
        "#         query = {'q': 'remdesivir OR HCQ OR hydrochloroquine OR vaccine OR favipiravir OR avigan OR toclizumav OR testing covid OR testing coronavirus' + \" until:\" + str(start_time_epoch + timestep) + \" since:\"+ str(start_time_epoch), #testing for COVID19 -- specific hashtag  \n",
        "#              # 'geocode': \"28.4868704,77.5207691,10km\",\n",
        "#             'count': 100,\n",
        "#             'lang': 'en',\n",
        "#             'tweet_mode' : 'extended'     \n",
        "#             }\n",
        "        query = {'q': 'migrant' + \" until:\" + str(start_time_epoch + timestep) + \" since:\"+ str(start_time_epoch), #testing for COVID19 -- specific hashtag  \n",
        "             # 'geocode': \"28.4868704,77.5207691,10km\",\n",
        "            'count': 100,\n",
        "            'lang': 'en',\n",
        "            'tweet_mode' : 'extended'     \n",
        "            }\n",
        "        try:\n",
        "            results = python_tweets.search(**query)#['statuses']\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "            print(\"waiting\")\n",
        "            time.sleep(100)\n",
        "            continue\n",
        "        print(start_time_epoch, len(results))\n",
        "        for status in results:\n",
        "#             print(status)\n",
        "#             print(json.dumps(\n",
        "#                 status,\n",
        "#                 sort_keys=True,\n",
        "#                 indent=4,\n",
        "#                 separators=(',', ': ')\n",
        "#                 ))\n",
        "            datadict['date'].append(status['created_at'])\n",
        "            datadict['full_text'].append(status['full_text'])\n",
        "            datadict['hashtag_mentions'].append(status['entities']['hashtags'])\n",
        "            datadict['url_mentions'].append([item['url'] for item in status['entities']['urls']])\n",
        "            datadict['user_mentions'].append(status['entities']['user_mentions'])\n",
        "            datadict['language_iso'].append(status['metadata']['iso_language_code'])\n",
        "            datadict['user_reply'].append(status['in_reply_to_user_id'])\n",
        "            datadict['status_reply'].append(status['in_reply_to_status_id'])\n",
        "            datadict['user_id'].append(status['user']['id'])\n",
        "            datadict['user_id_name'].append(status['user']['name'])\n",
        "            datadict['user_screen_name'].append(status['user']['screen_name'])\n",
        "            datadict['user_location'].append(status['user']['location'])\n",
        "            datadict['user_desc'].append(status['user']['description'])\n",
        "            datadict['user_followers'].append(status['user']['followers_count'])\n",
        "            datadict['user_friends'].append(status['user']['friends_count'])\n",
        "            datadict['user_created_at'].append(status['user']['created_at'])\n",
        "            datadict['user_favorites_count'].append(status['user']['favourites_count'])\n",
        "            datadict['user_statuses'].append(status['user']['statuses_count'])\n",
        "            datadict['lang'].append(status['lang'])\n",
        "            datadict['status_retweet'].append(status['retweet_count'])\n",
        "            datadict['status_favorites'].append(status['favorite_count'])\n",
        "            datadict['geo'].append(status['geo'])\n",
        "            datadict['coordinates'].append(status['coordinates'])\n",
        "            datadict['place'].append(status['place'])\n",
        "            \n",
        "            \n",
        "        \n",
        "        start_time_epoch+=timestep\n",
        "        \n",
        "        \n",
        "    df = pd.DataFrame(datadict)\n",
        "    return df\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dqLJ3ad2OkZ"
      },
      "source": [
        "import pandas as pd\n",
        "df = get_query_object(start_date, end_date, timedelta)\n",
        "df\n",
        "#df.to_csv(\"migrant_labourer.csv\")\n",
        "# Search tweets\n",
        "# dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': []}\n",
        "# for status in python_tweets.search(**query)['statuses']:\n",
        "#     #print(status)\n",
        "#     dict_['user'].append(status['user']['screen_name'])\n",
        "#     dict_['date'].append(status['created_at'])\n",
        "#     dict_['text'].append(status['text'])\n",
        "#     dict_['favorite_count'].append(status['favorite_count'])\n",
        "\n",
        "# # Structure data in a pandas DataFrame for easier manipulation\n",
        "# df = pd.DataFrame(dict_)\n",
        "# df.sort_values(by='favorite_count', inplace=True, ascending=False)\n",
        "# df.head(100)\n",
        "#migrant - mostly 30s, max 50 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBU1tMsc2Okc"
      },
      "source": [
        "tweets = df['statuses']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XyuYqqA2Okg"
      },
      "source": [
        "for item in tweets:\n",
        "    print(item['id'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}